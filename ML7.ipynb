{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Boosting in Machine Learning? Explain how it improves weak\n",
        "learners.\n",
        "In Machine Learning, **Boosting** is an ensemble technique that combines a series of \"Weak Learners\" to create a single \"Strong Learner.\"\n",
        "\n",
        "### 1. What is Boosting?\n",
        "\n",
        "Unlike Bagging (where models run in parallel), Boosting trains models **sequentially** (one after another). Each new model attempts to correct the errors made by the previous model.\n",
        "\n",
        "### 2. How it improves Weak Learners:\n",
        "\n",
        "A **Weak Learner** is a simple model (like a shallow Decision Tree) that performs only slightly better than random guessing. Boosting turns them into a strong model through these steps:\n",
        "\n",
        "* **Focus on Errors:** It starts by training a weak model on the entire dataset.\n",
        "* **Re-weighting:** It identifies the data points that the first model predicted incorrectly and gives them higher **weight** (importance).\n",
        "* **Sequential Learning:** The next weak learner is forced to focus more on those \"hard-to-predict\" cases.\n",
        "* **Combined Strength:** Finally, all the weak learners are combined (usually via a weighted average) to make a highly accurate final prediction.\n",
        "\n",
        "### Key Summary\n",
        "\n",
        "| Feature | Explanation |\n",
        "| --- | --- |\n",
        "| **Logic** | Learn from the mistakes of previous models. |\n",
        "| **Goal** | To reduce **Bias** and improve accuracy. |\n",
        "| **Examples** | AdaBoost, Gradient Boosting (GBM), XGBoost. |\n",
        "\n"
      ],
      "metadata": {
        "id": "o5sxcoLs7DDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the difference between AdaBoost and Gradient Boosting in terms\n",
        "of how models are trained?\n",
        "Both **AdaBoost** and **Gradient Boosting** are sequential ensemble methods, but they differ fundamentally in how they \"learn\" from previous mistakes.\n",
        "\n",
        "### Core Differences in Training\n",
        "\n",
        "| Feature | AdaBoost (Adaptive Boosting) | Gradient Boosting (GBM) |\n",
        "| --- | --- | --- |\n",
        "| **Strategy** | **Weights Adjustment:** It increases the weight of data points that were misclassified. | **Residual Fitting:** It trains the next model to predict the *errors* (residuals) of the previous model. |\n",
        "| **Model Goal** | Focuses on \"hard\" examples that previous models got wrong. | Focuses on minimizing a **Loss Function** using Gradient Descent. |\n",
        "| **Weak Learners** | Usually very simple trees called **Decision Stubs** (just one split). | Uses larger (though still shallow) **Decision Trees**. |\n",
        "| **Final Result** | A weighted majority vote (better models have a \"bigger say\"). | An additive sum of all models, scaled by a learning rate. |\n",
        "\n",
        "---\n",
        "\n",
        "### How they work (Simplified)\n",
        "\n",
        "1. **AdaBoost:** Imagine a teacher giving more \"homework\" (higher weight) to a student only on the specific questions they got wrong in a test. The next test will then focus heavily on those difficult topics.\n",
        "2. **Gradient Boosting:** Instead of changing weights, this method calculates the **gap** (residual) between the actual answer and the predicted answer. The next model is then trained specifically to fill that gap. It's like a sculptor who first makes a rough shape and then uses smaller tools to carve away the remaining errors.\n",
        "\n",
        "**Key Summary:** AdaBoost fixes errors by emphasizing **mislabeled points**, while Gradient Boosting fixes errors by optimizing a **loss function** (like MSE) through gradients.\n"
      ],
      "metadata": {
        "id": "Tp9Wcdeb7Pxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: How does regularization help in XGBoost?\n",
        "In XGBoost, regularization is a \"safety net\" that prevents the model from becoming too complex or **overfitting** the training data. Unlike standard Gradient Boosting, XGBoost includes regularization directly in its objective function.\n",
        "\n",
        "### How it Helps:\n",
        "\n",
        "1. **Controls Model Complexity:** It penalizes the model for having too many leaves or very large weights. This ensures the model stays simple and \"generalizes\" well to new, unseen data.\n",
        "2. **Prevents Overfitting:** By discouraging the model from fitting every tiny noise or outlier in the training set, regularization keeps the predictions stable.\n",
        "3. **Handles High-Dimensional Data:** It helps manage datasets with many features by shrinking the influence of less important variables.\n",
        "\n",
        "### The Two Main Types used in XGBoost:\n",
        "\n",
        "* **L1 Regularization (Lasso / ):** This can push some feature weights to exactly zero, effectively performing **feature selection**.\n",
        "* **L2 Regularization (Ridge / ):** This spreads the influence across features and prevents any single leaf node from having an extreme weight.\n",
        "\n",
        "---\n",
        "\n",
        "**Summary:** Regularization in XGBoost acts as a \"penalty\" for complexity. It forces the trees to be simple and robust, which is why XGBoost usually performs better than standard Gradient Boosting.\n"
      ],
      "metadata": {
        "id": "Lq3FCXIa7dv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Why is CatBoost considered efficient for handling categorical data?\n",
        "CatBoost (Categorical Boosting) is considered highly efficient because it is specifically designed to handle categorical features **natively**, meaning you don't need to manually convert text labels (like \"City\" or \"Color\") into numbers before training.\n",
        "\n",
        "### 1. Ordered Target Encoding\n",
        "\n",
        "Traditional methods like **One-Hot Encoding** create too many columns (high dimensionality), and **Label Encoding** can imply a fake mathematical order.\n",
        "\n",
        "* CatBoost uses a unique form of **Target Encoding**. It replaces a category with a number based on the average target value for that category.\n",
        "* To prevent \"Data Leakage\" (the model seeing the answer during training), it uses **Ordered Boosting**, which calculates these statistics based only on the data points that came *before* the current one in a random permutation.\n",
        "\n",
        "### 2. Handling High Cardinality\n",
        "\n",
        "CatBoost excels even when a feature has thousands of categories (like User IDs). It can handle these without the memory explosion that occurs in XGBoost or LightGBM when using One-Hot Encoding.\n",
        "\n",
        "### 3. Automatic Feature Combinations\n",
        "\n",
        "CatBoost automatically looks for combinations of categorical features (e.g., \"Country\" + \"Language\") and treats them as a single new feature. This helps the model capture complex relationships that you would otherwise have to build manually.\n",
        "\n",
        "### 4. Symmetric (Oblivious) Trees\n",
        "\n",
        "CatBoost builds **Symmetric Trees**, where the same split condition is used for all nodes at the same level.\n",
        "\n",
        "* This structure acts as a form of **regularization** to prevent overfitting.\n",
        "* It also makes the model **extremely fast** during prediction (inference), as the tree structure is much simpler to calculate than traditional trees.\n",
        "\n",
        "---\n",
        "\n",
        "**Summary Comparison**\n",
        "| Feature | XGBoost / LightGBM | CatBoost |\n",
        "| :--- | :--- | :--- |\n",
        "| **Preprocessing** | Manual (One-Hot / Label) | **Automatic (Native)** |\n",
        "| **Encoding** | Standard / Histogram | **Ordered Target Encoding** |\n",
        "| **Tree Structure** | Asymmetric | **Symmetric (Oblivious)** |\n"
      ],
      "metadata": {
        "id": "k_4Zfccp7ouH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some real-world applications where boosting techniques are\n",
        "preferred over bagging methods?\n",
        "While **Bagging** (like Random Forest) is great for reducing variance and handling noisy data, **Boosting** is preferred when **accuracy is the top priority** and you have enough data to avoid overfitting.\n",
        "\n",
        "Here are the key real-world applications where Boosting is typically the winner:\n",
        "\n",
        "### 1. Financial Risk & Fraud Detection\n",
        "\n",
        "Banks use Gradient Boosting (XGBoost/CatBoost) because these models are highly sensitive to subtle patterns.\n",
        "\n",
        "* **Why:** Fraudulent transactions are rare (imbalanced data). Boosting focuses on these \"hard-to-detect\" cases by iteratively correcting previous errors.\n",
        "\n",
        "### 2. Search Engine Ranking (LTR)\n",
        "\n",
        "Search engines like Google or Bing use a version of boosting called **LambdaMART** to rank results.\n",
        "\n",
        "* **Why:** Ranking is a complex task where the relative order of results matters more than simple classification. Boosting optimizes these complex loss functions more effectively than Bagging.\n",
        "\n",
        "### 3. Recommendation Systems\n",
        "\n",
        "E-commerce and streaming platforms (Netflix, Amazon) use Boosting to predict which product a user will click next.\n",
        "\n",
        "* **Why:** These systems handle high-cardinality categorical data (like User IDs or Product IDs). **CatBoost** is specifically preferred here because it handles these categories natively without huge manual preprocessing.\n",
        "\n",
        "### 4. Click-Through Rate (CTR) Prediction\n",
        "\n",
        "In digital advertising, models must predict if a user will click an ad.\n",
        "\n",
        "* **Why:** CTR data is often very \"sparse\" and complex. The sequential nature of Boosting allows it to capture the intricate relationships between user behavior and ad content better than independent trees in a Forest.\n",
        "\n",
        "### 5. Healthcare Diagnostics\n",
        "\n",
        "Boosting is used to predict the onset of diseases (like Diabetes or Heart Disease) from medical records.\n",
        "\n",
        "* **Why:** In medicine, a \"False Negative\" (missing a sick patient) is very costly. Boosting's ability to minimize **Bias** ensures the model is as precise as possible.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary: When to choose Boosting?\n",
        "\n",
        "| Choose Boosting If... | Choose Bagging If... |\n",
        "| --- | --- |\n",
        "| You need maximum **Accuracy**. | You need to avoid **Overfitting** above all. |\n",
        "| You have many **Categorical Features** (use CatBoost). | Your data is very **Noisy**. |\n",
        "| You are competing in **Kaggle** or Data Science competitions. | You want a model that is **harder to break** with outliers. |\n"
      ],
      "metadata": {
        "id": "xnBQ8i0l70-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Datasets:\n",
        "● Use sklearn.datasets.load_breast_cancer() for classification tasks.\n",
        "● Use sklearn.datasets.fetch_california_housing() for regression\n",
        "tasks.\n",
        "Question 6: Write a Python program to:\n",
        "● Train an AdaBoost Classifier on the Breast Cancer dataset\n",
        "● Print the model accuracy\n",
        "(Include your Python code and output in the code box below.) '''\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# 2. Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Initialize the AdaBoost Classifier\n",
        "# n_estimators=50 (number of weak learners), learning_rate=1.0\n",
        "model = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "\n",
        "# 4. Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"AdaBoost Classifier Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "wxr00lJBbPIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f934f9b8-6de3-4bce-9f0b-b4a8421f4c7a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 96.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Question 7: Write a Python program to:\n",
        "● Train a Gradient Boosting Regressor on the California Housing dataset\n",
        "● Evaluate performance using R-squared score\n",
        "(Include your Python code and output in the code box below.) '''\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "# 1. Load the California Housing dataset\n",
        "try:\n",
        "    housing = fetch_california_housing()\n",
        "except HTTPError as e:\n",
        "    print(f\"Error loading California Housing dataset: {e}\")\n",
        "    print(\"This often indicates a temporary network issue or the dataset source is unavailable.\")\n",
        "    print(\"Please try re-running the cell. If the issue persists, you might need to check your network connection or try again later.\")\n",
        "    # Exit or raise a different error if you want to stop execution\n",
        "    raise\n",
        "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "y = housing.target\n",
        "\n",
        "# 2. Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Initialize the Gradient Boosting Regressor\n",
        "# n_estimators: number of boosting stages to perform\n",
        "# learning_rate: shrinks the contribution of each tree\n",
        "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# 4. Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. Evaluate the performance using R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Gradient Boosting Regressor R-squared Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04geOcoj8NM5",
        "outputId": "86a1a5e0-2693-452c-f404-c4040225e8a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor R-squared Score: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Question 8: Write a Python program to:\n",
        "● Train an XGBoost Classifier on the Breast Cancer dataset\n",
        "● Tune the learning rate using GridSearchCV\n",
        "● Print the best parameters and accuracy\n",
        "(Include your Python code and output in the code box below.) '''\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# 2. Split the data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Initialize XGBoost Classifier\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# 4. Define the parameter grid for Learning Rate\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "# 5. Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# 6. Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 7. Get best parameters and make predictions with the best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# 8. Print results\n",
        "print(f\"Best Learning Rate: {best_params['learning_rate']}\")\n",
        "print(f\"Accuracy with Best Model: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "infKjJCF8fDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd99f2f7-dcb3-4764-b37c-c36b58b0dabc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Learning Rate: 0.2\n",
            "Accuracy with Best Model: 95.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:14:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Question 9: Write a Python program to:\n",
        "● Train a CatBoost Classifier\n",
        "● Plot the confusion matrix using seaborn\n",
        "(Include your Python code and output in the code box below.) '''\n",
        "# Install CatBoost if not already installed\n",
        "!pip install catboost\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# 1. Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# 2. Split the data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Initialize and Train CatBoost Classifier\n",
        "# 'verbose=0' keeps the output clean by hiding training logs\n",
        "model = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, verbose=0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 5. Create the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# 6. Plot the Confusion Matrix using Seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=data.target_names,\n",
        "            yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('CatBoost Classifier Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# 7. Print Accuracy\n",
        "print(f\"CatBoost Model Accuracy: {model.score(X_test, y_test) * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "WwNyty-D8no3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ff35168-114f-41e0-f52f-759cc6994bea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoost Model Accuracy: 96.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Question 10: You're working for a FinTech company trying to predict loan default using\n",
        "customer demographics and transaction behavior.\n",
        "The dataset is imbalanced, contains missing values, and has both numeric and\n",
        "categorical features.\n",
        "Describe your step-by-step data science pipeline using boosting techniques:\n",
        "● Data preprocessing & handling missing/categorical values\n",
        "● Choice between AdaBoost, XGBoost, or CatBoost\n",
        "● Hyperparameter tuning strategy\n",
        "● Evaluation metrics you'd choose and why\n",
        "● How the business would benefit from your model\n",
        "(Include your Python code and output in the code box below.) '''\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, average_precision_score\n",
        "\n",
        "# 1. Load Data (Using Breast Cancer as proxy for demo)\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target # 1 = Benign, 0 = Malignant (Let's assume 0 is 'Default')\n",
        "\n",
        "# 2. Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Handle Imbalance & Model Initialization\n",
        "# scale_pos_weight = (count of negative class) / (count of positive class)\n",
        "model = CatBoostClassifier(\n",
        "    iterations=200,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    auto_class_weights='Balanced', # Handles imbalanced data\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# 4. Train Model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predictions & Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 6. Output Results\n",
        "print(\"--- Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"PR-AUC Score: {average_precision_score(y_test, y_probs):.4f}\")\n"
      ],
      "metadata": {
        "id": "JQ_s0Q1a8whg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce58289-3e46-441a-c368-8fc0924bf6ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96        43\n",
            "           1       0.97      0.99      0.98        71\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n",
            "PR-AUC Score: 0.9984\n"
          ]
        }
      ]
    }
  ]
}